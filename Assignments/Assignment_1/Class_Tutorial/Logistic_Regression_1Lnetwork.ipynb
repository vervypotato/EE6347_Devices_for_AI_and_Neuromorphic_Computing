{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kSnG9Vr427J"
      },
      "source": [
        "## PART_A ######\n",
        "\n",
        "## 1.1 Importing the library and dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtEdnGA427K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b39c95b-4115-42d7-8b1a-e2043721911d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CDscAn7427N"
      },
      "source": [
        "Problem Statement: You are given a dataset (\"data.h5\") containing:\n",
        "\n",
        "- a training set of m_train images labeled as cat (y=1) or non-cat (y=0)\n",
        "- a test set of m_test images labeled as cat or non-cat\n",
        "- each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).\n",
        "You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat\n",
        "\n",
        "Let's get more familiar with the dataset. Load the data by running the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL1TAlgR427N"
      },
      "source": [
        "import sys\n",
        "path='//' #Set an appropriate path here. Make sure that the Cat-images dataset is in this folder.\n",
        "sys.path.append(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n"
      ],
      "metadata": {
        "id": "hxmT9-tHzSC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "    with h5py.File('path/train_catvnoncat.h5', \"r\") as train_dataset:\n",
        "        train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "        train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "    with h5py.File('/path/test_catvnoncat.h5', \"r\") as test_dataset:\n",
        "        test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "        test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "        classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes= load_data()\n",
        "\n"
      ],
      "metadata": {
        "id": "1mEyNQgTEjkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJbLCx1b427P"
      },
      "source": [
        "Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB5SsVS9427Q"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX8Z1ls6427T"
      },
      "source": [
        "**Exercise: Find the values for:**\n",
        "\n",
        "- m_train (number of training examples)\n",
        "- m_test (number of test examples)\n",
        "- num_px (= height = width of a training image)\n",
        "\n",
        "Remember that train_set_x_orig is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access m_train by writing train_set_x_orig.shape[0]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMHOhBDs427T"
      },
      "source": [
        "###Find the values for:\n",
        "\n",
        "m_train =\n",
        "m_test =\n",
        "num_px =\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3Zcvte427V"
      },
      "source": [
        "\n",
        "\n",
        "**Exercise:**\n",
        "Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFIRRWNB427W"
      },
      "source": [
        "####Reshape the training and test set\n",
        "\n",
        "train_set_x_flatten =\n",
        "test_set_x_flatten =\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXhvv1Og427Y"
      },
      "source": [
        "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
        "\n",
        "\n",
        "Let's normalize our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOQkMYyv427Y"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGWcNK_w427b"
      },
      "source": [
        "## PART_B ######\n",
        "\n",
        "It's time to design a simple algorithm to distinguish cat images from non-cat images.\n",
        "\n",
        "You will build a simple neural network with one neuron.\n",
        "\n",
        "\n",
        "Key steps: In this exercise, you will carry out the following steps:\n",
        "\n",
        "- Initialize the parameters of the model\n",
        "- Learn the parameters for the model by minimizing the cost  \n",
        "- Use the learned parameters to make predictions (on the test set)\n",
        "- Analyse the results and conclude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6TNb1PA427b"
      },
      "source": [
        "## Building the parts of our algorithm\n",
        "\n",
        "The main steps for building a Neural Network are:\n",
        "\n",
        "Define the model structure (such as number of input features)\n",
        "\n",
        "Initialize the model's parameters\n",
        "\n",
        "Loop:\n",
        "\n",
        "Calculate current loss (forward propagation)\n",
        "\n",
        "Calculate current gradient (backward propagation)\n",
        "\n",
        "Update the parameters (gradient descent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRv1EPF2427c"
      },
      "source": [
        "## HELPER FUNCTIONS ####\n",
        "\n",
        "### B.1  Exercise: Implement Sigmoid Function: sigmoid()\n",
        "\n",
        "ùëé= ùúé(ùëß)=  1/(1 + ùëíxp(‚àíùëß) )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wDKtKWR427c"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2o_EXdP427e"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9RyDauM427h"
      },
      "source": [
        "### B.2 Initializing Parameter\n",
        "\n",
        "i.e. w and b\n",
        "\n",
        "for network with single neuron we will initialize with random weights and zero bias."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cIp-5z8xy5-i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfcSCD15427h"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG7ObC9j427j"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYXU3YD1427m"
      },
      "source": [
        "### B.3 Forward and Backward Propogation\n",
        "you can do the \"forward\" and \"backward\" propagation steps for learning the parameters.\n",
        "\n",
        "**Exercise:** Implement a function `propagation()` that computes the cost function and its gradient.\n",
        "\n",
        "**Hints**:\n",
        "\n",
        "Forward Propagation:\n",
        "- You get X of dimension (n, m) n=no of input feture, m=no of training example\n",
        "- You compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
        "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
        "\n",
        "Here are the two formulas you will be using:\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
        "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_xOtMwI427m"
      },
      "source": [
        "###Graded Function: calculate forward and backward propogation\n",
        "\n",
        "def propagation():\n",
        "\n",
        "\n",
        "    return grads, cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34jBrUey427q"
      },
      "source": [
        "### B.4 - Optimization\n",
        "- You have initialized your parameters.\n",
        "- You are also able to compute a cost function and its gradient.\n",
        "- Now, you want to update the parameters using gradient descent.\n",
        "\n",
        "**Exercise:** Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_UKBShK427r"
      },
      "source": [
        "def optimization():\n",
        "\n",
        "\n",
        "\n",
        "     return params, grads, costs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWqeYMI5427v"
      },
      "source": [
        "**Exercise:** The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the `predict()` function. There are two steps to computing predictions:\n",
        "\n",
        "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
        "\n",
        "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxixdOxp427v"
      },
      "source": [
        "# GRADED FUNCTION: predict\n",
        "\n",
        "def predict():\n",
        "\n",
        "\n",
        "\n",
        "    return Y_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1hwh288427x",
        "outputId": "c3aa5ac0-903e-423b-e2e5-3509fd86209a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w = np.array([[0.1124579],[0.23106775]])\n",
        "b = -0.3\n",
        "X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
        "print (\"predictions = \" + str(predict(w, b, X)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions = [[1. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ6tET6g427z"
      },
      "source": [
        "## C - Merge all functions into a model ##\n",
        "\n",
        "You will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.\n",
        "\n",
        "**Exercise:** Implement the model function. Use the following notation:\n",
        "    - Y_prediction_test for your predictions on the test set\n",
        "    - Y_prediction_train for your predictions on the train set\n",
        "    - w, costs, grads for the outputs of optimization()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cz1kclg4270"
      },
      "source": [
        "# GRADED FUNCTION: model\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations = 200000, learning_rate = 0.5, print_cost = False):\n",
        "\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # initialize parameters with zeros (‚âà 1 line of code)\n",
        "    w, b = rand_init(X_train.shape[0])\n",
        "     #w,b = rand_init(X_train.shape[0])\n",
        "\n",
        "    # Gradient descent (‚âà 1 line of code)\n",
        "    parameters, grads, costs = optimization(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost = False)\n",
        "\n",
        "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
        "    w = parameters[\"w\"]\n",
        "    b = parameters[\"b\"]\n",
        "\n",
        "    # Predict test/train set examples (‚âà 2 lines of code)\n",
        "    Y_prediction_test = predict(w, b, X_test)\n",
        "    Y_prediction_train = predict(w, b, X_train)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Print train/test Errors\n",
        "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
        "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
        "\n",
        "\n",
        "    d = {\"costs\": costs,\n",
        "         \"Y_prediction_test\": Y_prediction_test,\n",
        "         \"Y_prediction_train\" : Y_prediction_train,\n",
        "         \"w\" : w,\n",
        "         \"b\" : b,\n",
        "         \"learning_rate\" : learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ww7t_S9uRkK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}